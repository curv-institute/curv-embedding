# Implementation Output — Stability-Driven Chunking for Vector Database Embeddings

**Timestamp**: 2026-01-16
**Run ID**: 1768588892

## Summary

Successfully implemented the complete v0.1 stability-driven chunking system for vector database embeddings, including offline and streaming modes, evaluation metrics, and paper artifact generation.

## Implemented Components

### 1. Chunking Module (`src/chunking/`)

#### cut_score.py
- `CutScoreSignals` dataclass for raw signals (K, S, D, B, L)
- `NormalizedSignals` dataclass for z-score normalized values
- `RollingNormalizer` class for streaming z-score computation with O(1) updates
- `SignalNormalizers` for managing independent normalizers per signal
- `compute_cut_score()` implementing the full formula:
  ```
  cut_score(t) = wK*relu(K̃-k0) + wD*relu(D̃-d0) + wS*relu(s0-S̃) + wB*B + wL*relu((L-L_target)/L_target)
  ```

#### offline.py
- `Chunk` dataclass with byte offsets, content, cut-score, and signals
- Signal simulation for v0.1:
  - K (curvature): local byte entropy
  - S (stability): inverse byte variance
  - B (structural): newline detection
- `chunk_offline()`: full-document chunking with local maxima selection

#### streaming.py
- `BoundaryCandidate` dataclass for tracking candidates in commit horizon
- `StreamingChunkerState` for maintaining buffer and trigger state
- `chunk_stream()`: iterator-based streaming with hard/soft triggers
- `StreamingChunker` class: stateful API with `feed()` and `finalize()`

#### manifests.py
- `ChunkMetadata` and `ChunkManifest` dataclasses
- `generate_manifest()`: creates manifest with SHA256 hashes and config
- `validate_manifest()` and `verify_chunk_integrity()`

### 2. Data Generation (`src/data/`)

#### generator.py
- `SyntheticDocument` dataclass with boundary_offsets and planted_anchors
- Domain-specific generators:
  - `generate_text_document()`: Markov-like prose with paragraph boundaries
  - `generate_code_document()`: Python-like code with function boundaries
  - `generate_json_document()`: JSON arrays with object boundaries
  - `generate_log_document()`: Timestamped logs with entry boundaries
- `generate_corpus()`: multi-domain corpus generation

#### manifests.py
- `DataManifest` and `QueryFamily` dataclasses
- `generate_query_families()`: reformulation families with domain-specific templates
- `generate_anchors_manifest()`: detailed anchor metadata

### 3. Embedding Module (`src/embedding/`)

#### model.py
- `EmbeddingModel` class wrapping sentence-transformers
- Version-pinned model loading via config
- `embed()`, `embed_single()`, `model_info()`, `embedding_checksum()`

#### vectors.py
- `cosine_similarity()`, `l2_distance()`, `normalize_vectors()`
- `vectors_to_bytes()`, `bytes_to_vectors()` for serialization

### 4. Storage Module (`src/storage/`)

#### sqlite_store.py
- `ChunkRecord` dataclass mapping to schema
- `SQLiteStore` class with WAL mode:
  - `add_document()`, `add_chunk()`, `update_chunk_*()` methods
  - `log_event()` for audit logging
  - `start_ingestion_run()`, `complete_ingestion_run()`
  - Context manager and transaction support

#### faiss_index.py
- `FAISSIndex` class wrapping FAISS Flat index
- `add_vectors()`, `search()`, `get_neighbors()`
- `save()`, `load()` with metadata persistence

### 5. Evaluation Metrics (`src/eval/`)

#### drift.py
- `compute_drift_cosine()`, `compute_drift_l2()`
- `DriftResult` dataclass with mean/p90 and distributions
- `compute_drift_stats()` for matched embedding pairs

#### churn.py
- `compute_topk_overlap()`, `compute_jaccard()`, `compute_rank_correlation()`
- `ChurnResult` dataclass
- `compute_churn_stats()` aggregation

#### overlap.py
- `compute_hit_rate()`, `compute_reformulation_stability()`
- `OverlapResult` with per-family statistics

#### maintenance.py
- `MaintenanceResult` and `MaintenanceSummary` dataclasses
- `compute_maintenance_stats()`, `compute_cumulative_maintenance()`

#### plots.py
- `set_paper_style()` for academic figures
- `plot_drift_distribution()`, `plot_churn_over_updates()`
- `plot_overlap_by_k()`, `plot_chunk_size_distribution()`
- `plot_boundary_sensitivity()`

### 6. CLI Scripts (`scripts/`)

All scripts use PEP 723 inline dependencies and are executable via `uv run`:

| Script | Purpose |
|--------|---------|
| `run_experiment.py` | Main experiment runner (baseline vs stability-driven) |
| `make_data.py` | Synthetic corpus generation |
| `chunk_offline.py` | Offline chunking CLI |
| `chunk_stream.py` | Streaming chunking CLI |
| `embed_index.py` | Embedding and FAISS index building |
| `query_eval.py` | Query evaluation with families |
| `report.py` | Report and LaTeX table generation |
| `reproduce.py` | Reproducibility verification |
| `test_all.py` | Test suite (11 tests) |

## Test Results

```
Running tests...

  [PASS] Config: config module OK
  [PASS] Cut Score: cut_score module OK
  [PASS] Offline Chunking: offline chunking OK
  [PASS] Streaming Chunking: streaming chunking OK
  [PASS] Data Generator: data generator OK
  [PASS] Manifests: manifests OK
  [PASS] Vectors: vectors OK
  [PASS] Drift Metrics: drift metrics OK
  [PASS] Churn Metrics: churn metrics OK
  [PASS] Overlap Metrics: overlap metrics OK
  [PASS] Maintenance Metrics: maintenance metrics OK

11 passed, 0 failed
```

## Repository Structure

```
curv-embedding/
├── AGENTS.md                    # Agent rules
├── CLAUDE.md                    # Canonical Prompt Contract
├── AGENT/                       # Prompt archival
│   ├── 1768588892-in.md
│   └── 1768588892-out.md
├── VERSION                      # 0.1.0
├── CITATION.cff
├── CHANGELOG.md
├── ARTIFACT_CHECKLIST.md
├── configs/
│   └── default.toml            # Full configuration
├── scripts/                     # PEP 723 executables
├── src/
│   ├── config.py               # Typed configuration loader
│   ├── chunking/               # Cut-score, offline, streaming
│   ├── data/                   # Generator, manifests
│   ├── embedding/              # Model, vectors
│   ├── storage/                # SQLite, FAISS
│   └── eval/                   # Metrics, plots
├── paper/
│   ├── main.tex
│   ├── references.bib
│   └── artifact_appendix.tex
├── eval/results/               # Per-run output
└── tests/
```

## Configuration (configs/default.toml)

Key settings:
- Chunk size: 256-4096 bytes (target 2048)
- Cut-score weights: wK=1.0, wD=0.8, wS=0.6, wB=2.0, wL=0.5
- Embedding: sentence-transformers/all-MiniLM-L6-v2 (384-dim)
- Storage: SQLite WAL mode + FAISS Flat index
- Evaluation: top-k = [10, 50, 100]

## Commits

1. `8a39c31` - Initialize repository structure
2. `53549f7` - Implement stability-driven chunking (25 files, 7568 insertions)

## Next Steps

1. Run full experiment: `uv run scripts/run_experiment.py --run-name v0.1_baseline`
2. Generate reports: `uv run scripts/report.py --run-name v0.1_baseline`
3. Verify reproducibility: `uv run scripts/reproduce.py --run-name v0.1_baseline`
