# Claude Experiment Prompt — v1.3.0 Streaming Parity (Offline vs Streaming Chunking)

You are Claude Code, acting as a senior ML systems engineer and research engineer.

This prompt runs a contained streaming parity cycle for curv-embedding and releases v1.3.0. The goal is to show that streaming chunking approximates offline chunking under bounded lookahead, without any retrieval evaluation yet.

Must comply with CLAUDE.md, AGENTS.md, AGENT archival, jj/git discipline, and minor version auto-tagging.

---

## Canonical Start Prompt (Authoritative)

Context: Continue the curv-embedding project. v1.2.0 contains the first offline experiment matrix. This cycle evaluates streaming chunking parity only.

Goal: Implement and evaluate streaming chunking mode and quantify how closely it matches offline chunking on the same deterministic dataset.

Hypothesis: With bounded lookahead and commit horizon, streaming chunking produces chunk boundaries and size distributions that closely approximate offline chunking, with small, explainable deviations near commitment windows and boundaries.

Constraints: deterministic, reproducible, no changes to chunking semantics beyond enabling streaming execution path; no retrieval evaluation.

Deliverables: streaming experiment runs, parity metrics (boundary overlap, size distribution), paper-ready plots/tables, manifests.

Non-goals: embedding drift, ANN churn, query reformulation, reranking, or any retrieval claims.

---

## Scope (Strict)

Allowed changes:
- Add/enable a streaming execution path in scripts (if missing)
- Add parity metrics and reporting
- Add tests for streaming determinism and parity invariants

Not allowed:
- Changing the cut-score formula
- Changing proxy diagnostics computation
- Changing embedding model/index behavior

---

## Required Metrics (Authoritative)

Compute and report:

### 1. Chunk count parity
- n_chunks_offline
- n_chunks_streaming
- delta_pct

### 2. Size distribution parity
- mean/p50/p90 chunk sizes for each
- Wasserstein-1 distance (or KS statistic) between size distributions
- fraction of chunks within ±10% of L_target_bytes

### 3. Boundary placement overlap

Represent boundaries as byte offsets (end offsets) in the original byte stream.
- boundary_overlap@tol:
  - for each offline boundary, count a match if a streaming boundary exists within ±tol_bytes
  - report for tol_bytes ∈ {0, 16, 64, 256}
- Precision/Recall/F1:
  - precision = matched_streaming / total_streaming
  - recall = matched_offline / total_offline

### 4. Deviation localization (diagnostic)

Report where mismatches occur:
- fraction of mismatches within ±commit_horizon of an offline boundary
- fraction of mismatches near known domain boundaries (if manifest provides offsets)

No retrieval metrics.

---

## Runs (Name exactly like this)

Use today's date as YYYYMMDD.
- Offline stability chunking:
  - v1.2.0-offline-parity-YYYYMMDD
- Streaming stability chunking:
  - v1.2.0-streaming-parity-YYYYMMDD

Both runs must use identical:
- dataset
- diagnostics.mode=proxy_entropy
- [chunking] parameters (except streaming-only knobs like commit horizon)

---

## Execution Plan (Parallelize)

- Subagent A: ensure streaming run path exists (scripts/chunk_stream.py or run_experiment --mode streaming)
- Subagent B: run offline parity experiment + validate artifacts
- Subagent C: run streaming parity experiment + validate artifacts
- Subagent D: implement parity metrics + report/plots + paper artifacts
- Subagent E: tests (streaming determinism; manifest consistency)

---

## Steps (Do in Order)

### 0) AGENT archive (mandatory)
- Compute UNIX time <T>.
- Save this prompt to AGENT/<T>-in.md.

### 1) Checkout latest tag and set up env

```bash
git checkout v1.2.0
uv venv .venv
source .venv/bin/activate
```

### 2) Generate or reuse deterministic dataset

Use the same dataset as v1.2.0. If regeneration is required, ensure manifests match.

```bash
uv run scripts/make_data.py --output-dir eval/data
```

### 3) Run offline vs streaming chunking

If run_experiment.py supports modes:

```bash
uv run scripts/run_experiment.py --run-name v1.2.0-offline-parity-YYYYMMDD --mode offline
uv run scripts/run_experiment.py --run-name v1.2.0-streaming-parity-YYYYMMDD --mode streaming
```

If modes are separate scripts:

```bash
uv run scripts/chunk_offline.py --run-name v1.2.0-offline-parity-YYYYMMDD
uv run scripts/chunk_stream.py --run-name v1.2.0-streaming-parity-YYYYMMDD
```

Both runs must write per-run artifacts under eval/results/<run_name>/ with:
- chunk manifests containing boundary offsets
- summary.json containing chunk statistics

No FAISS indexing required in this parity cycle.

### 4) Compute parity metrics

Add a comparison script (or extend report.py) to compute parity metrics and emit:
- eval/results/comparisons/v1.2.0-parity-YYYYMMDD/summary.json
- paper/tables/chunk_parity_v1.2.0.tex
- paper/figures/chunk_parity_sizes_v1.2.0.pdf
- paper/figures/chunk_parity_overlap_v1.2.0.pdf

### 5) Validate
- Confirm both runs are deterministic (repeat run with same seed yields identical boundaries)
- Confirm manifests include:
  - diagnostics.mode
  - chunking parameters including commit horizon

### 6) Record execution output

Write an execution summary to AGENT/<T>-out.md including:
- parity metrics table
- any deviations and where they localize
- whether deviations are attributable to commit horizon

Commit and push AGENT files.

---

## Suggested Reporting Additions (Apply)

Add a quantitative replacement for "Target Alignment: Good/Poor":
- %within_10pct_target = fraction(|L - L_target|/L_target <= 0.10)

Report it for offline and streaming.

---

## Post-cycle release: v1.3.0 (mandatory)

After parity work completes:
- Switch back to main
- Merge changes (if any) cleanly
- Update VERSION to 1.3.0
- Add CHANGELOG.md entry:

```markdown
## v1.3.0
- Add streaming chunking parity evaluation (offline vs streaming)
- Report boundary overlap and size-distribution parity metrics
- Add %within_10pct_target alignment metric
- AGENT prompt used: `AGENT/<T>-in.md`
```

- Commit via jj, push, tag annotated v1.3.0, push tags.

---

## Stop Condition

Stop when:
- streaming mode exists and runs
- parity metrics computed and plotted
- paper artifacts generated
- AGENT archive committed/pushed
- v1.3.0 tagged and pushed

Do not add retrieval evaluation in this cycle.
