# Claude Experiment Prompt — v1.4.0 Temporal Stability (Drift & Churn under Updates)

You are Claude Code, acting as a senior ML systems engineer and research engineer.

This prompt runs the temporal stability experiment cycle for curv-embedding and releases v1.4.0. It measures how stability-driven chunking behaves over time under updates, now that offline and streaming parity has been established.

Must comply with CLAUDE.md, AGENTS.md, AGENT archival, jj/git discipline, and minor version auto-tagging.

---

## Canonical Start Prompt (Authoritative)

Context: Continue the curv-embedding project. v1.3.0 established that streaming chunking approximates offline segmentation within the commit horizon. This cycle evaluates temporal stability under updates.

Goal: Quantify embedding drift, ANN neighbor churn, and maintenance cost when documents are incrementally updated, comparing heuristic chunking vs stability-driven chunking.

Hypothesis: Stability-driven chunking localizes representational change over time, resulting in lower embedding drift, lower neighbor churn, and fewer re-embeds than heuristic chunking under equivalent updates.

Constraints: deterministic, reproducible, no semantic or algorithmic changes to chunking/embedding logic; use existing FAISS + SQLite pipeline.

Deliverables: per-update experiment runs, drift/churn/maintenance metrics, paper-ready tables and figures, manifests.

Non-goals: query reformulation, reranking, ANN replacement, benchmark accuracy optimization.

---

## Scope (Strict)

Allowed changes:
- Add/update scripts to simulate temporal updates (append/edit/delete)
- Add temporal comparison metrics and plots

Not allowed:
- Modifying cut-score or diagnostics computation
- Changing embedding model or FAISS index type
- Changing chunking parameters mid-run

---

## Update Scenarios (Authoritative)

Simulate updates to the same corpus over time:

### 1. Append-only
- Append new content blocks to existing documents

### 2. Local edits
- Small edits within existing documents (no full rewrites)

### 3. Boundary stress
- Updates near known chunk boundaries

Each scenario must preserve content identity via content_sha256 so unchanged chunks can be compared across time.

---

## Required Metrics (Authoritative)

Compute metrics before and after each update step.

### A) Embedding drift (content-stable chunks)

For chunks with identical content_sha256 across revisions:
- drift_cos = 1 - cosine(e_t, e_{t+1})
- drift_l2 = ||e_t - e_{t+1}||_2

Report mean, p90, and distribution plots.

---

### B) ANN neighbor churn

For a fixed probe set of query vectors or chunk vectors:
- topk_overlap@k
- jaccard@k

Compare:
- pre-update vs post-update
- baseline vs stability-driven

---

### C) Maintenance cost
- reembed_fraction = (# chunks re-embedded) / (# total chunks)
- index_rebuild_events
- index_rebuild_time

---

### D) Boundary-localized effects

Using boundary offsets:
- drift and churn within ±N bytes of original boundaries
- compare to interior regions

---

## Runs (Name exactly like this)

Use today's date as YYYYMMDD.

Baseline heuristic chunking:
- v1.3.0-baseline-temporal-YYYYMMDD

Stability-driven chunking:
- v1.3.0-stability-temporal-YYYYMMDD

If streaming is used, suffix with -streaming.

---

## Execution Plan (Parallelize)

- Subagent A: implement update simulation + content identity tracking
- Subagent B: run baseline temporal experiment + validate artifacts
- Subagent C: run stability temporal experiment + validate artifacts
- Subagent D: metrics aggregation + plots + paper artifacts
- Subagent E: tests (temporal determinism, identity invariants)

---

## Steps (Do in Order)

### 0) AGENT archive (mandatory)
- Compute UNIX time <T>.
- Save this prompt to AGENT/<T>-in.md.

### 1) Checkout latest tag and set up env

```bash
git checkout v1.3.0
uv venv .venv
source .venv/bin/activate
```

### 2) Prepare temporal datasets

Extend or reuse data generator to emit:
- base corpus (t0)
- updated corpus versions (t1, t2)

Ensure manifests link updates to original doc_id and content_sha256.

---

### 3) Run temporal experiments

```bash
uv run scripts/run_experiment.py --run-name v1.3.0-baseline-temporal-YYYYMMDD
uv run scripts/run_experiment.py --run-name v1.3.0-stability-temporal-YYYYMMDD
```

Each run must:
- write per-run artifacts
- log update step in manifest
- checkpoint SQLite WAL at each step

---

### 4) Aggregate temporal metrics

Generate reports showing:
- drift over time (t0→t1→t2)
- neighbor churn over time
- re-embed fraction per update scenario

Write outputs to:
- paper/tables/temporal_stability_v1.3.0.tex
- paper/figures/temporal_drift_v1.3.0.pdf
- paper/figures/temporal_churn_v1.3.0.pdf

---

### 5) Record execution output

Write a concise execution summary to AGENT/<T>-out.md including:
- key metric deltas
- scenario-specific observations
- any failures or anomalies

Commit and push AGENT files.

---

## Minor Reporting Note (Mandatory)

In all tables/figures/captions, explicitly state the commit horizon used (e.g., commit_horizon_bytes = 256) so readers can interpret boundary-localized results.

---

## Post-cycle release: v1.4.0 (mandatory)

After experiments complete:
- Update VERSION to 1.4.0
- Add CHANGELOG.md entry:

```markdown
## v1.4.0
- Add temporal stability evaluation under incremental updates
- Measure embedding drift, ANN neighbor churn, and maintenance cost
- Report boundary-localized effects with explicit commit horizon
- AGENT prompt used: `AGENT/<T>-in.md`
```

- Commit via jj, push, tag annotated v1.4.0, push tags.

---

## Stop Condition

Stop when:
- temporal runs complete
- drift/churn/maintenance metrics computed
- paper artifacts generated
- AGENT archive committed and pushed
- v1.4.0 tagged and pushed

Do not introduce reranking or retrieval changes in this cycle.
